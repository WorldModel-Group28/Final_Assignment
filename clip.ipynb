{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: torchvision in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: filelock in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: numpy in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: requests in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from requests->torchvision) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-ypii0hsy\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-ypii0hsy\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from clip==1.0) (6.1.3)\n",
      "Requirement already satisfied: regex in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from clip==1.0) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from clip==1.0) (4.66.1)\n",
      "Requirement already satisfied: torch in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from clip==1.0) (2.2.0)\n",
      "Requirement already satisfied: torchvision in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from clip==1.0) (0.17.0)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torch->clip==1.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->clip==1.0) (12.3.101)\n",
      "Requirement already satisfied: numpy in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torchvision->clip==1.0) (1.26.3)\n",
      "Requirement already satisfied: requests in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torchvision->clip==1.0) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from torchvision->clip==1.0) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/kako/anaconda3/envs/myenv/lib/python3.9/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install git+https://github.com/openai/CLIP.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 76\u001b[0m\n\u001b[1;32m     72\u001b[0m             results_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_choice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 43\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m results_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_results.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(results_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m results_file:    \n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m     44\u001b[0m         image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(images_dir, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     45\u001b[0m         text_description \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_description\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/csv.py:110\u001b[0m, in \u001b[0;36mDictReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;66;03m# Used only for its side effect.\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfieldnames\u001b[49m\n\u001b[1;32m    111\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mline_num\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/csv.py:97\u001b[0m, in \u001b[0;36mDictReader.fieldnames\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fieldnames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fieldnames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import clip\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "def load_clip_model():\n",
    "    # Load the CLIP model from OpenAI\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "    return model, preprocess, device\n",
    "\n",
    "def predict_choice(model, preprocess, device, image_path, text_descriptions):\n",
    "    # Preprocess the image and tokenize the text descriptions\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    text_tokens = clip.tokenize(text_descriptions).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode image and text with the CLIP model\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(text_tokens)\n",
    "\n",
    "        # Calculate the similarity scores and convert to probabilities\n",
    "        logits_per_image = (image_features @ text_features.T).softmax(dim=-1)\n",
    "        probs = logits_per_image.cpu().numpy()\n",
    "\n",
    "    return probs[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    model, preprocess, device = load_clip_model()\n",
    "    base_dir = \"past_data/clip_dataset\"\n",
    "    images_dir = os.path.join(base_dir, \"images\")\n",
    "    csv_file_path = os.path.join(base_dir, \"dataset.csv\")\n",
    "\n",
    "    with open(csv_file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        # 結果を保存するファイルを開く\n",
    "    results_file_path = os.path.join(base_dir, \"clip_results.txt\")\n",
    "    with open(results_file_path, 'w', newline='', encoding='utf-8') as results_file:    \n",
    "        for row in reader:\n",
    "            image_path = os.path.join(images_dir, row[\"image_filename\"])\n",
    "            text_description = row[\"text_description\"]\n",
    "            choices = row[\"button_texts\"].split('|')\n",
    "\n",
    "            # 'many' が text_description に含まれているかをチェック\n",
    "            if \"many\" in text_description:\n",
    "                parts = text_description.split(\" \")\n",
    "                try:\n",
    "                    items_index = parts.index(\"many\") + 1\n",
    "                    items_phrase = \" \".join(parts[items_index:-2]) \n",
    "                except ValueError:\n",
    "                    # 'many' の後に 'are there' が見つからない場合はスキップ\n",
    "                    print(f\"Error in text description for image: {row['image_filename']}\")\n",
    "                    continue\n",
    "\n",
    "                # 各選択肢に対する説明文を生成\n",
    "                text_descriptions = [f\"There are {choice} {items_phrase}.\" for choice in choices]\n",
    "            else:\n",
    "                # 'many' がなければ、デフォルトのフレーズを使用\n",
    "                text_descriptions = [f\"There are {choice} items.\" for choice in choices]\n",
    "\n",
    "            # CLIPモデルによる予測\n",
    "            probs = predict_choice(model, preprocess, device, image_path, text_descriptions)\n",
    "            best_choice_index = probs.argmax()\n",
    "            selected_choice = choices[best_choice_index] if choices[best_choice_index] != ' ' else 'No valid choice'\n",
    "            print(f\"Image: {row['image_filename']}, Best choice: {selected_choice}, Probability: {probs[best_choice_index]:.4f}\")\n",
    "            \n",
    "\n",
    "            results_file.write(f\"{selected_choice}\\n\")\n",
    "\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: image_0001.png, Best choice: 3, Probability: 0.3972\n",
      "Image: image_0002.png, Best choice: 0, Probability: 0.2296\n",
      "Image: image_0003.png, Best choice: 0, Probability: 0.2129\n",
      "Image: image_0004.png, Best choice: No valid choice, Probability: 0.2367\n",
      "Image: image_0005.png, Best choice: 3, Probability: 0.2705\n",
      "Image: image_0006.png, Best choice: 2, Probability: 0.4575\n",
      "Image: image_0007.png, Best choice: 2, Probability: 0.3918\n",
      "Image: image_0008.png, Best choice: 2, Probability: 0.4099\n",
      "Image: image_0009.png, Best choice: 1, Probability: 0.2292\n",
      "Image: image_0010.png, Best choice: 2, Probability: 0.7500\n",
      "Image: image_0011.png, Best choice: 1, Probability: 0.2500\n",
      "Image: image_0012.png, Best choice: 3, Probability: 0.3281\n",
      "Image: image_0013.png, Best choice: 0, Probability: 0.1383\n",
      "Image: image_0014.png, Best choice: 3, Probability: 0.3506\n",
      "Image: image_0015.png, Best choice: 3, Probability: 0.3540\n",
      "Image: image_0016.png, Best choice: No valid choice, Probability: 0.2064\n",
      "Image: image_0017.png, Best choice: 2, Probability: 0.3562\n",
      "Image: image_0018.png, Best choice: 1, Probability: 0.1694\n",
      "Image: image_0019.png, Best choice: 9, Probability: 0.2566\n",
      "Image: image_0020.png, Best choice: 0, Probability: 0.2615\n",
      "Image: image_0021.png, Best choice: 4, Probability: 0.4617\n",
      "Image: image_0022.png, Best choice: 2, Probability: 0.2235\n",
      "Image: image_0023.png, Best choice: 3, Probability: 0.2615\n",
      "Image: image_0024.png, Best choice: 2, Probability: 0.3923\n",
      "Image: image_0025.png, Best choice: 4, Probability: 0.2322\n",
      "Image: image_0026.png, Best choice: 3, Probability: 0.2389\n",
      "Image: image_0027.png, Best choice: 0, Probability: 0.1725\n",
      "Image: image_0028.png, Best choice: 3, Probability: 0.4146\n",
      "Image: image_0029.png, Best choice: 0, Probability: 0.2920\n",
      "Image: image_0030.png, Best choice: 7, Probability: 0.2390\n",
      "Image: image_0031.png, Best choice: 2, Probability: 0.5361\n",
      "Image: image_0032.png, Best choice: 3, Probability: 0.3511\n",
      "Image: image_0033.png, Best choice: 0, Probability: 0.1919\n",
      "Image: image_0034.png, Best choice: 0, Probability: 0.3311\n",
      "Image: image_0035.png, Best choice: 3, Probability: 0.2773\n",
      "Image: image_0036.png, Best choice: 2, Probability: 0.3347\n",
      "Image: image_0037.png, Best choice: 3, Probability: 0.2747\n",
      "Image: image_0038.png, Best choice: No valid choice, Probability: 0.1362\n",
      "Image: image_0039.png, Best choice: 6, Probability: 0.3147\n",
      "Image: image_0040.png, Best choice: 0, Probability: 0.2428\n",
      "Image: image_0041.png, Best choice: No valid choice, Probability: 0.1599\n",
      "Image: image_0042.png, Best choice: 2, Probability: 0.2893\n",
      "Image: image_0043.png, Best choice: 3, Probability: 0.2367\n",
      "Image: image_0044.png, Best choice: 2, Probability: 0.2571\n",
      "Image: image_0045.png, Best choice: 3, Probability: 0.2944\n",
      "Image: image_0046.png, Best choice: No valid choice, Probability: 0.2101\n",
      "Image: image_0047.png, Best choice: 2, Probability: 0.2720\n",
      "Image: image_0048.png, Best choice: 2, Probability: 0.3528\n",
      "Image: image_0049.png, Best choice: 2, Probability: 0.3035\n",
      "Image: image_0050.png, Best choice: 1, Probability: 0.1882\n",
      "Image: image_0051.png, Best choice: 2, Probability: 0.3240\n",
      "Image: image_0052.png, Best choice: 2, Probability: 0.4431\n",
      "Image: image_0053.png, Best choice: 2, Probability: 0.3774\n",
      "Image: image_0054.png, Best choice: 3, Probability: 0.2512\n",
      "Image: image_0055.png, Best choice: No valid choice, Probability: 0.2170\n",
      "Image: image_0056.png, Best choice: 4, Probability: 0.2761\n",
      "Image: image_0057.png, Best choice: No valid choice, Probability: 0.1609\n",
      "Image: image_0058.png, Best choice: 2, Probability: 0.3611\n",
      "Image: image_0059.png, Best choice: 5, Probability: 0.1884\n",
      "Image: image_0060.png, Best choice: 3, Probability: 0.2279\n",
      "Image: image_0061.png, Best choice: 2, Probability: 0.2637\n",
      "Image: image_0062.png, Best choice: 4, Probability: 0.1995\n",
      "Image: image_0063.png, Best choice: 3, Probability: 0.2281\n",
      "Image: image_0064.png, Best choice: 4, Probability: 0.3386\n",
      "Image: image_0065.png, Best choice: No valid choice, Probability: 0.1809\n",
      "Image: image_0066.png, Best choice: 3, Probability: 0.3870\n",
      "Image: image_0067.png, Best choice: 2, Probability: 0.3640\n",
      "Image: image_0068.png, Best choice: 2, Probability: 0.2747\n",
      "Image: image_0069.png, Best choice: 2, Probability: 0.3201\n",
      "Image: image_0070.png, Best choice: 2, Probability: 0.2207\n",
      "Image: image_0071.png, Best choice: 0, Probability: 0.3369\n",
      "Image: image_0072.png, Best choice: 2, Probability: 0.5366\n",
      "Image: image_0073.png, Best choice: 2, Probability: 0.4136\n",
      "Image: image_0074.png, Best choice: 2, Probability: 0.3638\n",
      "Image: image_0075.png, Best choice: 1, Probability: 0.1949\n",
      "Image: image_0076.png, Best choice: 1, Probability: 0.2385\n",
      "Image: image_0077.png, Best choice: 3, Probability: 0.3909\n",
      "Image: image_0078.png, Best choice: 1, Probability: 0.2524\n",
      "Image: image_0079.png, Best choice: 2, Probability: 0.2534\n",
      "Image: image_0080.png, Best choice: 6, Probability: 0.2211\n",
      "Image: image_0081.png, Best choice: 3, Probability: 0.2225\n",
      "Image: image_0082.png, Best choice: 3, Probability: 0.3699\n",
      "Image: image_0083.png, Best choice: 7, Probability: 0.2091\n",
      "Image: image_0084.png, Best choice: 2, Probability: 0.4138\n",
      "Image: image_0085.png, Best choice: 3, Probability: 0.4412\n",
      "Image: image_0086.png, Best choice: 0, Probability: 0.2279\n",
      "Image: image_0087.png, Best choice: 3, Probability: 0.1527\n",
      "Image: image_0088.png, Best choice: 6, Probability: 0.2632\n",
      "Image: image_0089.png, Best choice: 2, Probability: 0.1731\n",
      "Image: image_0090.png, Best choice: 0, Probability: 0.3596\n",
      "Image: image_0091.png, Best choice: 9, Probability: 0.2727\n",
      "Image: image_0092.png, Best choice: 4, Probability: 0.2367\n",
      "Image: image_0093.png, Best choice: No valid choice, Probability: 0.1686\n",
      "Image: image_0094.png, Best choice: 2, Probability: 0.3877\n",
      "Image: image_0095.png, Best choice: 2, Probability: 0.2499\n",
      "Image: image_0096.png, Best choice: 2, Probability: 0.5850\n",
      "Image: image_0097.png, Best choice: 4, Probability: 0.3464\n",
      "Image: image_0098.png, Best choice: 2, Probability: 0.3801\n",
      "Image: image_0099.png, Best choice: 3, Probability: 0.3960\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import clip\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "def load_clip_model():\n",
    "    # Load the CLIP model from OpenAI\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "    return model, preprocess, device\n",
    "\n",
    "def predict_choice(model, preprocess, device, image_path, text_descriptions):\n",
    "    # Preprocess the image and tokenize the text descriptions\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    text_tokens = clip.tokenize(text_descriptions).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode image and text with the CLIP model\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(text_tokens)\n",
    "\n",
    "        # Calculate the similarity scores and convert to probabilities\n",
    "        logits_per_image = (image_features @ text_features.T).softmax(dim=-1)\n",
    "        probs = logits_per_image.cpu().numpy()\n",
    "\n",
    "    return probs[0]\n",
    "\n",
    "\n",
    "def main():\n",
    "    model, preprocess, device = load_clip_model()\n",
    "    base_dir = \"past_data/clip_dataset\"\n",
    "    images_dir = os.path.join(base_dir, \"images\")\n",
    "    csv_file_path = os.path.join(base_dir, \"dataset.csv\")\n",
    "    results_file_path = os.path.join(base_dir, \"clip_results.txt\")\n",
    "\n",
    "    with open(csv_file_path, 'r', newline='', encoding='utf-8') as file, open(results_file_path, 'w', newline='', encoding='utf-8') as results_file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            image_path = os.path.join(images_dir, row[\"image_filename\"])\n",
    "            text_description = row[\"text_description\"]\n",
    "            choices = row[\"button_texts\"].split('|')\n",
    "\n",
    "            # 'many' が text_description に含まれているかをチェック\n",
    "            if \"many\" in text_description:\n",
    "                parts = text_description.split(\" \")\n",
    "                try:\n",
    "                    items_index = parts.index(\"many\") + 1\n",
    "                    items_phrase = \" \".join(parts[items_index:-2]) \n",
    "                except ValueError:\n",
    "                    # 'many' の後に 'are there' が見つからない場合はスキップ\n",
    "                    print(f\"Error in text description for image: {row['image_filename']}\")\n",
    "                    continue\n",
    "\n",
    "                # 各選択肢に対する説明文を生成\n",
    "                text_descriptions = [f\"There are {choice} {items_phrase}.\" for choice in choices]\n",
    "            else:\n",
    "                # 'many' がなければ、デフォルトのフレーズを使用\n",
    "                text_descriptions = [f\"There are {choice} items.\" for choice in choices]\n",
    "                \n",
    "            # CLIPモデルによる予測と結果の書き出し\n",
    "           \n",
    "            probs = predict_choice(model, preprocess, device, image_path, text_descriptions)\n",
    "            best_choice_index = probs.argmax()\n",
    "            selected_choice = choices[best_choice_index] if choices[best_choice_index] != ' ' else 'No valid choice'\n",
    "            print(f\"Image: {row['image_filename']}, Best choice: {selected_choice}, Probability: {probs[best_choice_index]:.4f}\")\n",
    "            \n",
    "            results_file.write(f\"{selected_choice}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
